{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites: python 3.6 or later\n",
    "import requests\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For real interactions with the data catalog, use api.mint-data-catalog.org\n",
    "url = \"https://sandbox.mint-data-catalog.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you register datasets or resources, we require you to pass a \"provenance_id\". This a unique id associated\n",
    "# with your account so that we can keep track of who is adding things to the data catalog. For sandboxed interactions\n",
    "# with the data catalog api, please use this provenance_id:\n",
    "provenance_id = \"e8287ea4-e6f2-47aa-8bfc-0c22852735c8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get session token to use the API\n",
    "resp = requests.get(f\"{url}/get_session_token\").json()\n",
    "print(resp)\n",
    "api_key = resp['X-Api-Key']\n",
    "\n",
    "request_headers = {\n",
    "    'Content-Type': \"application/json\",\n",
    "    'X-Api-Key': api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our setup\n",
    "#\n",
    "# Recall from the data catalog primer (https://docs.google.com/document/d/1I3CjYB-GDdFTZO-dHsHB0B5f0iEbzHnr8QHSKN5k3Sc/edit#heading=h.crwrtnf2ch1h) \n",
    "# that a *dataset* is logical grouping of data about specific *variables* contained in one or more *resources*\n",
    "#\n",
    "# To make the above statement more concrete, we will interactively go through the process of registering a toy\n",
    "# dataset in the data catalog in order to make it available for others.\n",
    "#\n",
    "# Let's say I have a dataset called \"Temperature recorded outside my house\" in which every day I note the\n",
    "# temperature outside my apartment in the morning, afternoon, and evening. I then record those data points in a \n",
    "# csv file temp_records_YYYY_MM_DD.csv that looks like:\n",
    "#\n",
    "# |        Time         | Temperature |\n",
    "# -------------------------------------\n",
    "# | 2018-01-01T07:34:40 |    23       |\n",
    "# | 2018-01-01T12:15:28 |    32       |\n",
    "# | 2018-01-01T20:56:15 |    26       |\n",
    "#\n",
    "# Note that each file contains data for a single day only. \n",
    "#\n",
    "# In this example, my dataset would be \"Temperature recorded outside my house\", variables would be \n",
    "# \"Time\" and \"Temperature\", and each csv file would be a resource associated with the dataset. In addition,\n",
    "# since each file contains both of the variables in our dataset, each resource will be associated with both variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, *I* know that what I refer to as \"Temperature\" is actually the air temperature recorded in F, but my CSV\n",
    "# files have no mention of the fact. If you just look at the file without any context, it's unclear what it is that \n",
    "# is being recorded. Temperature of what? In what units? C, F, K?\n",
    "#\n",
    "# In order to disambiguate those variable names, we require that each variable in your dataset to be associated\n",
    "# with one or more *standard* variables. What makes a variable name \"standard\" is that it is a part of some ontology,\n",
    "# so that anyone can examine that ontology and see for themselves semantic meaning of the variable.\n",
    "# Most of our current datasets are mapped to standard names defined by the GSN ontology. \n",
    "# But you are not forced to map your variables to GSN names. Data catalog allows you to register your own set \n",
    "# of standard_variable_names. The only requirement for now is that those standard names are associated with an\n",
    "# ontology whose schema is publicly available.\n",
    "# \n",
    "# @param[name] standard variable name (aka label)\n",
    "# @param[ontology] name of the ontology where standard variables are defined\n",
    "# @param[uri] uri of standard variable name (note that this is full uri, which includes the ontology)\n",
    "standard_variable_defs = {\n",
    "    \"standard_variables\": [\n",
    "        {\n",
    "            \"name\": \"Time_Standard_Variable\",\n",
    "            \"ontology\": \"MyOntology\",\n",
    "            \"uri\": \"http://my_ontology_uri.org/standard_names/time_standard_variable\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Temperature_Standard_Variable\",\n",
    "            \"ontology\": \"MyOntology\",\n",
    "            \"uri\": \"http://my_ontology_uri.org/standard_names/temperature_standard_variable\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/knowledge_graph/register_standard_variables\", \n",
    "                    headers=request_headers, \n",
    "                    json=standard_variable_defs).json()\n",
    "\n",
    "print(resp)\n",
    "\n",
    "# If request is successful, it will return 'result': 'success' along with a list of registered standard variables\n",
    "# and their record_ids. Those record_ids are unique identifiers (UUID) and you will need them down the road to \n",
    "# register variables\n",
    "if resp['result'] == 'success':\n",
    "    records = resp['standard_variables']\n",
    "    time_standard_variable = next(record for record in records if record[\"name\"] == \"Time_Standard_Variable\")\n",
    "    temperature_standard_variable = next(record for record in records if record[\"name\"] == \"Temperature_Standard_Variable\")\n",
    "    \n",
    "    print(f\"Time Standard Variable: {time_standard_variable}\")\n",
    "    print(f\"Temperature Standard Variable: {temperature_standard_variable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to check if specific standard variables have already been registered in the data catalog, \n",
    "# you can search by name and data catalog will return existing records.\n",
    "nonexistent_name = str(uuid.uuid4())\n",
    "print(f\"This name does not exist: {nonexistent_name}\")\n",
    "\n",
    "search_query = {\n",
    "    \"name__in\": [\"Time_Standard_Variable\", \"Temperature_Standard_Variable\", nonexistent_name]\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/knowledge_graph/find_standard_variables\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=search_query).json()\n",
    "\n",
    "if resp['result'] == 'success':\n",
    "    existing_standard_variables = resp[\"standard_variables\"]\n",
    "    print(existing_standard_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you are satisfied that all relevant standard variables are in the data catalog (usually it's a one-time thing),\n",
    "# you can proceed to register datasets, variables, and resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Register datasets\n",
    "dataset_uuid = \"4e8ade31-7729-4891-a462-2dac66158512\" # This is optional; if not given, it will be auto-generated\n",
    "\n",
    "dataset_defs = {\n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"record_id\": dataset_uuid,\n",
    "            \"provenance_id\": provenance_id,\n",
    "            \"metadata\": {\"any_additional_metadata\": \"content\"},\n",
    "            \"description\": \"Temperature recorded outside my house; collected over last month\",\n",
    "            \"name\": \"Temperature recorded outside my house\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/datasets/register_datasets\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=dataset_defs).json()\n",
    "\n",
    "\n",
    "if resp['result'] == 'success':\n",
    "    datasets = resp[\"datasets\"]\n",
    "    print(datasets)\n",
    "    \n",
    "    dataset_record = next(record for record in datasets if record[\"name\"] == \"Temperature recorded outside my house\")\n",
    "    dataset_record_id = dataset_record[\"record_id\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Register variables\n",
    "\n",
    "# Again, these ids are optional and will be auto-generated if not given. They are included here in order\n",
    "# to make requests indempotent (so that new records aren't beeing generated every time this code block is run)\n",
    "\n",
    "time_variable_record_id = '9358af57-192f-4cc3-9bee-837e76819674'\n",
    "temperature_variable_record_id = 'c22deb3b-ebda-48cb-950a-2f4f00498197'\n",
    "\n",
    "variable_defs = {\n",
    "    \"variables\": [\n",
    "        {\n",
    "            \"record_id\": time_variable_record_id,\n",
    "            \"dataset_id\": dataset_record_id,\n",
    "            \"name\": \"Time\",\n",
    "            \"metadata\": {\n",
    "                \"units\": \"ISO8601_datetime\"\n",
    "            },\n",
    "            \"standard_variable_ids\": [\n",
    "                time_standard_variable[\"record_id\"]\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"record_id\": temperature_variable_record_id,\n",
    "            \"dataset_id\": dataset_record_id,\n",
    "            \"name\": \"Temperature\",\n",
    "            \"metadata\": {\n",
    "                \"units\": \"F\"\n",
    "            },\n",
    "            \"standard_variable_ids\": [\n",
    "                temperature_standard_variable[\"record_id\"]\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/datasets/register_variables\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=variable_defs).json()\n",
    "\n",
    "\n",
    "if resp['result'] == 'success':\n",
    "    variables = resp[\"variables\"]\n",
    "    \n",
    "    time_variable = next(record for record in variables if record[\"name\"] == \"Time\")\n",
    "    temperature_variable = next(record for record in variables if record[\"name\"] == \"Temperature\")\n",
    "    \n",
    "    print(f\"Time Variable: {time_variable}\")\n",
    "    print(f\"Temperature Variable: {temperature_variable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Register resources\n",
    "# Assume that I host my datasets files on www.my_domain.com/storage\n",
    "data_storage_url = \"www.my_domain.com/storage\"\n",
    "\n",
    "# Also, assume that I've collected 2 days worth of data\n",
    "# in temp_records_2018_01_01.csv and temp_records_2018_01_02.csv. \n",
    "file_1_name = \"temp_records_2018_01_01.csv\"\n",
    "file_2_name = \"temp_records_2018_01_02.csv\"\n",
    "\n",
    "# and uploaded them to my remote storage location\n",
    "file_1_data_url = f\"{data_storage_url}/{file_1_name}\"\n",
    "file_2_data_url = f\"{data_storage_url}/{file_2_name}\"\n",
    "\n",
    "# Similar to dataset and variable registrations, we are going to generate unique resource record_ids to \n",
    "# make these requests repeatable without creating new records. But remember, these will \n",
    "\n",
    "file_1_record_id = \"dd52e66b-3149-4d46-8f8e-a18e46136e55\"\n",
    "file_2_record_id = \"25916ccf-d108-4187-b243-2b257ce67fa5\"\n",
    "\n",
    "# Next, let's say that my house is somewhere in LA, \n",
    "# defined by the following bounding box (where x refers to longitude and y refers to latitude)\n",
    "# x_min:  33.9605286\n",
    "# y_min: -118.4253354\n",
    "# x_max: 33.9895077\n",
    "# y_max: -118.4093589\n",
    "\n",
    "# If I want my resources to be searchable by time range, I can \"annotate\" each resource with corresponding \n",
    "# temporal coverage. That way, when someone searches for any datasets that contain \"Temperature_Standard_Variable\"\n",
    "# for January 01 2018, my file_1_name will be returned, along with the data url, and the users will be able to \n",
    "# download it easily. Note that temporal coverage must have \"start_time\" and \"end_time\" and must follow ISO 8601 \n",
    "# datetime format YYYY-MM-DDTHH:mm:ss\n",
    "\n",
    "file_1_temporal_coverage = {\n",
    "    \"start_time\": \"2018-01-01T00:00:00\",\n",
    "    \"end_time\": \"2018-01-01T23:59:59\"\n",
    "}\n",
    "file_2_temporal_coverage = {\n",
    "    \"start_time\": \"2018-01-02T00:00:00\",\n",
    "    \"end_time\": \"2018-01-02T23:59:59\"\n",
    "}\n",
    "\n",
    "# Similarly, if I want my datasets to be searchable by location, I can annotate them with spatial coverage. Since\n",
    "# they are from the same location, we can reuse the same values. Things to note here are required \"type\" and \"value\"\n",
    "# parameters\n",
    "spatial_coverage = {\n",
    "    \"type\": \"BoundingBox\",\n",
    "    \"value\": {\n",
    "        \"xmin\": 33.9605286,\n",
    "        \"ymin\": -118.4253354,\n",
    "        \"xmax\": 33.9895077,\n",
    "        \"ymax\": -118.4093589\n",
    "    }\n",
    "}\n",
    "\n",
    "# Now we can build our resource definitions\n",
    "\n",
    "resource_defs = {\n",
    "    \"resources\": [\n",
    "        {\n",
    "            \"record_id\": file_1_record_id,\n",
    "            \"dataset_id\": dataset_record_id,\n",
    "            \"provenance_id\": provenance_id,\n",
    "            \"variable_ids\": [\n",
    "                time_variable[\"record_id\"],\n",
    "                temperature_variable[\"record_id\"]\n",
    "            ],\n",
    "            \"name\": file_1_name,\n",
    "            \"resource_type\": \"csv\",\n",
    "            \"data_url\": file_1_data_url,\n",
    "            \"metadata\": {\n",
    "                \"spatial_coverage\": spatial_coverage,\n",
    "                \"temporal_coverage\": file_1_temporal_coverage\n",
    "            },\n",
    "            \"layout\": {}\n",
    "        },\n",
    "        {\n",
    "            \"record_id\": file_2_record_id,\n",
    "            \"dataset_id\": dataset_record_id,\n",
    "            \"provenance_id\": provenance_id,\n",
    "            \"variable_ids\": [\n",
    "                time_variable[\"record_id\"],\n",
    "                temperature_variable[\"record_id\"]\n",
    "            ],\n",
    "            \"name\": file_2_name,\n",
    "            \"resource_type\": \"csv\",\n",
    "            \"data_url\": file_2_data_url,\n",
    "            \"metadata\": {\n",
    "                \"spatial_coverage\": spatial_coverage,\n",
    "                \"temporal_coverage\": file_2_temporal_coverage\n",
    "            },\n",
    "            \"layout\": {}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ... and register them in bulk\n",
    "resp = requests.post(f\"{url}/datasets/register_resources\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=resource_defs).json()\n",
    "\n",
    "\n",
    "if resp['result'] == 'success':\n",
    "    resources = resp[\"resources\"]\n",
    "    \n",
    "    resource_1 = next(record for record in resources if record[\"name\"] == file_1_name)\n",
    "    resource_2 = next(record for record in resources if record[\"name\"] == file_2_name)\n",
    "    \n",
    "    print(f\"{file_1_name}: {resource_1}\")\n",
    "    print(f\"{file_2_name}: {resource_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can search for data\n",
    "# 1) Searching by standard_names\n",
    "\n",
    "search_query_1 = {\n",
    "    \"standard_variable_names__in\": [temperature_standard_variable[\"name\"]]\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/datasets/find\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=search_query_1).json()\n",
    "if resp['result'] == 'success':\n",
    "    found_resources = resp['resources']\n",
    "    print(f\"Found {len(found_resources)} resources\")\n",
    "    print(found_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Searching by spatial_coverage\n",
    "\n",
    "# Bounding box search parameter is a 4-element numeric array (in WGS84 coordinate system) [xmin, ymin, xmax, ymax]\n",
    "# As a reminder, x is longitude, y is latitude\n",
    "bounding_box = [\n",
    "    spatial_coverage[\"value\"][\"xmin\"], \n",
    "    spatial_coverage[\"value\"][\"ymin\"], \n",
    "    spatial_coverage[\"value\"][\"xmax\"],\n",
    "    spatial_coverage[\"value\"][\"ymax\"]\n",
    "]\n",
    "\n",
    "search_query_2 = {\n",
    "    \"spatial_coverage__within\": bounding_box\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/datasets/find\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=search_query_2).json()\n",
    "if resp['result'] == 'success':\n",
    "    found_resources = resp['resources']\n",
    "    print(f\"Found {len(found_resources)} resources\")\n",
    "    print(found_resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Searching by temporal_coverage and standard_names\n",
    "\n",
    "# Bounding box search parameter is a 4-element numeric array (in WGS84 coordinate system) [xmin, ymin, xmax, ymax]\n",
    "# As a reminder, x is longitude, y is latitude\n",
    "start_time = \"2018-01-01T00:00:00\"\n",
    "end_time = \"2018-01-01T23:59:59\"\n",
    "\n",
    "search_query_3 = {\n",
    "    \"standard_variable_names__in\": [temperature_standard_variable[\"name\"]],\n",
    "    \"start_time__gte\": start_time,\n",
    "    \"end_time__lte\": end_time\n",
    "}\n",
    "\n",
    "resp = requests.post(f\"{url}/datasets/find\", \n",
    "                                        headers=request_headers,\n",
    "                                        json=search_query_3).json()\n",
    "\n",
    "if resp['result'] == 'success':\n",
    "    found_resources = resp['resources']\n",
    "    print(f\"Found {len(found_resources)} resources\")\n",
    "    print(found_resources)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
